# Binary Heap

In fact, besides search trees, there are other types of trees capable of efficiently performing certain operations. One such structure is a **binary heap**, which can quickly perform the following operations:

- add a value;
- get / remove the extremum.

In the future, without loss of generality, we will refer to a binary heap **for minimum**, unless explicitly stated otherwise.

Also, in the context of this lecture, we will use the word "heap" as a synonym for binary heap unless otherwise specified.

## Internal Structure

### Heap Property

A binary heap is a binary tree, and for any pair "parent $p$ - child $v$", it holds that the value in $p$ is not greater than the value in $v$.

This property is called the "**heap property**," and it is what allows the efficient execution of the operations described above.

For example, due to the heap property, the root node contains the minimum element. Thus, accessing the extremum is done in $O(1)$.

### Binary Tree, But Not Search Tree

Note that the heap property only works for the pair "parent - child." It does not say anything about the relationship between two children of the same node.

Thus, the values in the left and right children of a node (and, accordingly, in the subtrees) are not related to each other. This leads to the fact that a heap **cannot** efficiently perform **searching** for a value - there is not enough information to correctly choose a path when descending.

### Almost Complete Tree

A heap is an **almost complete** tree: if the height of the heap is $H$, then all layers from $1$ to $H - 1$ are completely filled, and only the last layer may be partially filled "from left to right."

Thus, in a heap with height $H$, there can be from $2^{H - 1}$ to $2^H - 1$ nodes.

If there are a total of $N$ nodes in the heap, then it follows that $H \in [\log{(N + 1)}; \log{N} + 1] = O(\log{N})$.

From this, it follows that a heap is a **balanced** binary tree.

#### Array Implementation

Since a heap is a balanced binary tree, it can be efficiently implemented **in an array** using the following numbering:

- the root is at position $1$;
- the left child of node $v$ has number $2 \cdot v$, the right child - $2 \cdot v + 1$.
  - thus, the number of the parent of node $v$ is $\lfloor\frac{v}{2}\rfloor$.

You can find additional information about this implementation method in [the lecture on binary trees](https://gist.github.com/Slamur/d856357624ac9b3afdbaf99dbb0bace9#идентификаторы-позиции-в-массиве).

## Operations

The heap property is its most important **invariant**. Therefore, after any change to the heap, additional actions are necessary to maintain the invariant - upheap and downheap.

### Upheap

This process restores the invariant if node $v$ is initially located **lower** than it should be.

While node $v$ is not the root of the tree, we will iteratively perform the following operations:

- let $p$ be the current parent of node $v$;
- if $value_p \le value_v$, then the process is complete;
- otherwise, the heap property for the pair $(p, v)$ is violated - we will fix this by swapping $p$ and $v$.

In the worst case, there will be $H - 1 = O(H) = O(\log{N})$ upheap iterations.

#### Example Implementation in C++

```cpp
void up_heap(size_t v) {
  while (v != root) {
    size_t p = v / 2;
    if (values[p] <= values[v]) break;

    std::swap(values[p], values[v]);
    v = p;
  }
}
```

### Downheap

This process restores the invariant if node $v$ is initially located **higher** than it should be.

While $v$ is not a leaf node of the tree, we will perform the following operations:

- let $vl$ and $vr$ be the current children of node $v$;
- let $value_{vl} < value_{vr}$ (for the reverse case, the actions are analogous);
- if $value_v \le value_{vl}$, then the process is complete;
- otherwise, the heap property for the pair $(v, vl)$ is violated - we will fix this by swapping $v$ and $vl$.

In the worst case, there will be $H - 1 = O(H) = O(\log{N})$ downheap iterations.

#### Example Implementation in C++

```cpp
void down_heap(size_t v) {
  while (true) {
    size_t min_v = v;

    size_t vl = v * 2;
    if (vl < values.size() && values[min_v] > values[vl]) min_v = vl;

    size_t vr = vl + 1;
    if (vr < values.size() && values[min_v] > values[vr]) min_v = vr;

    if (v == min_v) break;

    std::swap(values[v], values[min_v]);
    v = min_v;
  }
}
```

### Adding a Value

The bottom layer of the heap is usually filled "from left to right." In the case of an array implementation, this means that all nodes from $1$ to $N$ are filled.

Therefore, we will add a new value in the smallest free position $(N + 1)$. Such an addition could only violate the invariant relative to the parent of this value, so we will call **upheap** to fix the invariant.

#### Example Implementation in C++

```cpp
void push(T value) {
  values[++last] = value;
  up_heap(last);
}
```

### Accessing the Extremum

This operation does not make any changes to the heap, so no additional actions are required.

As you remember, the extremum always lies in the root node of the tree, so access is performed in $O(1)$.

#### Example Implementation in C++

```cpp
T top() {
  return values[root];
}
```

### Removing the Extremum

Finding and removing the extremum is not difficult - you already know that it is located in the root node.

The main problem is maintaining the integrity of the heap after deletion.

It may seem that one can simply place one of its children in the root's place. The resulting "hole" can be iteratively closed by descending lower and lower.

The problem is that after such a fix, the heap will almost certainly cease to be an almost complete tree.

Instead, we will place the node located at position $N$ (the last occupied position) in the root's place.

This action may violate the heap property for the new root and its children, so we will call **downheap** for the root to fix the invariant.

#### Example Implementation in C++

```cpp
void pop() {
  std::swap(values[root], values[last--]);
  down_heap(root);
}
```

### Insertion with Removal of the Extremum

In some situations, the size of the heap must remain constant - accordingly, when adding a new value, it is necessary to remove the extremum.

Yes, one can perform two independent operations `push` and `pop`, but in this situation, they can be combined.

- If the new value is less than or equal to the extremum, then we do not change the heap at all - after all, the new value will be removed.
- Otherwise, we will place the new value **immediately** in the root position and call downheap. Thus, the root will be removed, and the new value will be correctly placed in the heap.

This method allows us to skip the upheap stage - the asymptotic complexity does not change, but the total number of node movements decreases.

#### Example Implementation in C++

```cpp
void pushpop(T value) {
  if (value <= values[root]) return;

  values[root] = value;
  downheap(root);
}
```

## Construction

### Sequential Insertions

We will start with an empty heap and insert elements one by one using the `push` operation.

Suppose we insert $N \le 2^H - 1$ values. In the worst case, each new value will rise from the bottom to the root, so the total number of rises will be $0 \cdot 2^0 + 1 \cdot 2^1 + \dots + (H - 1) \cdot 2^{(H - 1)}$.

In the end, we get $2^H \cdot H - 2 \cdot (2^H - 1) = O(H \cdot 2^H)$ for all $N$ insertion operations.

Since $H = O(\log_2{N})$, it follows that $O(H \cdot 2^H) = O(\log{N} \cdot N)$, from which the amortized estimate for inserting a value when building a heap is $O(\log{N})$.

The result may seem obvious (after all, we already knew that insertion in a heap works in $O(\log{N})$), but in general, the asymptotic complexity of building a structure from scratch is not as obvious as it seems.

### Based on an Entire Sequence

Given a sequence $a$ of length $N \le 2^H - 1$, we need to build a heap based on it.

First, we will copy the sequence into an array, on which the heap will be built. Then we will iterate over the elements from $N$ to $1$, calling **downheap** for each element.

The algorithm is correct since at each call to downheap, both subtrees of the current vertex already satisfy the heap property.

In the worst case, each node will descend to level $H$, meaning there will be a total of $0 \cdot 2^{H - 1} + 1 \cdot 2^{H - 2} + \dots + (H - 1) \cdot 2^0$ descents.

In the end, we get $2^H - H + 1 = O(2^H)$ down operations for the entire construction. Since $H = O(\log_2{N})$, it follows that $O(2^H) = O(N)$.

This approach to transforming an array into a heap is called **heapify**.

It can be noted that this method is asymptotically more efficient than $N$ sequential insertions. At the same time, in most situations, the scenario of initially building a heap will not play a decisive role in the final efficiency of the algorithm.

#### Example Implementation in C++

In this example, 0-indexing of the array and heap is used. The formulas for parents and children are slightly modified, but this does not affect the essence.

```cpp
void heapify(std::vector<T>& values) {
  for (size_t v = values.size(); v > 0; --v) {
    down_heap(values, v - 1);
  }
}
```

## Modifications

### Removing Non-Extremum

Sometimes it is necessary to remove a specified value from the heap, not just the extremum.

#### Internal Processing

Additionally, we will maintain a dictionary "value - corresponding node in the tree." If duplicate values can be stored, a queue of nodes is maintained (the first in the queue is always removed).

Thus, when requesting to remove node $v$, it is sufficient to move the last element of the heap there, after which we will call upheap and downheap in sequence.

Both procedures need to be called since, in this case, it is unknown in which direction the heap property is violated when inserting the last element.

#### Example Implementation in C++

```cpp
void erase(const T& value) {
  size_t v = nodes[value];

  std::swap(values[v], values[last]);
  nodes[values[v]] = v;

  up_heap(v);
  down_heap(v);
}
```

#### External Processing

More often, the internal structure of the heap cannot be changed, so a method similar to removing from a queue is used.

A second heap with the same extremum rules is added, after which the removal request is split into two actions:

- when the removal request is made, the original heap is not changed, and the sought value is inserted into the second heap;
- before accessing/removing the extremum, iterative removal of the extremums of both heaps is performed if they match.

#### Example Implementation in C++

```cpp
void erase(Heap& remove_heap, const T& value) {
  removeHeap.push(value);
}

void ensure(Heap& heap, Heap& remove_heap) {
  while (remove_heap.size() > 0 && heap.top() == remove_heap.top()) {
    heap.pop();
    remove_heap.pop();
  }
}

T top(Heap& heap, Heap& remove_heap) {
  ensure(heap, remove_heap);
  return heap.top();
}

void pop(Heap& heap, Heap& remove_heap) {
  ensure(heap, remove_heap);
  heap.pop();
}
```

### Changing the Value in a Node

In essence, this scenario can be represented as removing the old value and inserting the new value.

With internal processing (position dictionary), one can use the `push_pop` paradigm - inserting the new value immediately in place of the old one, after which upheap and downheap are called.

With external processing (second heap), the new value can be inserted immediately, and the old one can be removed "on demand."

## Heap or Search Tree?

The implementation of a heap in an array (compared to nodes in dynamic memory in most search trees) allows for reduced costs for both adding new nodes and accessing existing nodes.

Therefore, although heap operations have similar asymptotic complexity to search trees at $O(\log{N})$, in most situations, they turn out to be **non-asymptotically more efficient**.

In most tasks, this difference will not be of significant importance, but in cases of time efficiency issues, heaps should be considered first.

## Other Heaps

In fact, a binary heap is just one of many families of heaps.

Examples of existing heaps:

- binomial heap;
- Fibonacci heap;
- leftist heap;
- and many others.

All heaps are trees (or a set of trees) and have a similar set of basic operations but may have improved asymptotic complexities for some of them.

Unlike binary heaps, most heaps are built on nodes in dynamic memory, which can negatively affect the final constant. Therefore, the binary heap is the simplest and sufficiently efficient choice for most situations.

# Heap Sort

It is easy to understand that using a heap, one can perform sorting in $O(N \cdot \log{N})$ with $N$ calls to `extract_extremum`.

## With Additional Memory

We build a minimum heap as a separate data structure based on an array.

After that, we sequentially extract the minimum value and insert it into the corresponding position.

#### Example Implementation in C++

```cpp
void sort(std::vector<T>& a) {
  heap_min h(a.begin(), a.end());

  for (size_t i = 0; i < a.size(); ++i) {
    a[i] = h.top();
    h.pop();
  }
}
```

## Without Additional Memory

In fact, it is possible to sort an array using the idea of a binary heap without additional memory.

- We will perform **heapify on maximum** on this array.
- We will iteratively perform `extract_extremum` and insert the obtained maximum into the corresponding position at the end of the array.

Thus, on the $i$-th iteration, positions $[1; i]$ will store values according to the heap property, while positions $[i + 1; N]$ will be in sorted order.

#### Example Implementation in C++

```cpp
void sort(std::vector<T>& a) {
  heapify_max(a);

  for (size_t i = a.size(); i > 0; --i) {
    std::swap(a[0], a[i - 1]);
    down_heap(a, 0);
  }
}
```