# Theoretical Foundations of Sorting

## Lower Bound of Sorting Efficiency through Comparisons

If sorting is based on comparisons (order relation), then its efficiency concerning the number of comparisons is $\Omega(N \cdot \log{N})$.

Note: this is a **lower** estimate of efficiency.

Most **built-in sorts** in languages have a complexity of $O(N \cdot \log{N})$ in average and/or worst cases.

### What about Counting Sort?

Counting sort **does not use comparisons** in the sorting process, as it is applied to data types for which strict order relations and "next value" are defined by default.

In general, the complexity of counting sort is $O(N + \max{A})$, which imposes strong limitations on its use.

At the same time, if the use of counting sort is possible - it can be more efficient than standard comparison-based sorts.

## Number of Inversions - Measure of Sequence Orderliness

An **inversion** in a sequence $a$ is a pair $a_i > a_j$ given that $i < j$.

If the sequence $a$ is sorted in the order of the relation $\le$, then the number of inversions is $0$.

If the sequence $a$ is sorted in the order of the relation $\ge$, then the number of inversions is $C(n, 2)$, where

- $n$ - the length of the sequence $a$.
- $C(n, k)$ - the binomial coefficient.
  - $C(n, 2) = \frac{n \cdot (n - 1)}{2}$ - in fact, each pair of elements is an inversion.

# Quadratic Sorts

In further descriptions, it is assumed that a sequence $a$ of length $n$ is sorted concerning the operation $\le$.

## Bubble Sort

- $n - 1$ iterations are performed.
- In the $i$-th iteration, the elements $a_1, a_2, \dots, a_{n - i}$ are processed.
- If $a_i > a_{i + 1}$, they are swapped.

Thus, an invariant is maintained - after the $i$-th iteration, the suffix $a_{n - i + 1} \dots a_n$ is sorted.

This process is very similar to the rise of a bubble in boiling water, hence the name of the sort.

The worst-case complexity is $O(n + (n - 1) + \dots + 1) = O(n^2)$ comparisons.

A modification of this sort to $O(n \cdot \log{n})$ is _quick sort_.

### Implementation

Example implementation in C++:

```cpp
for (size_t i = 0; i + 1 < n; ++i)
{
  for (size_t j = 0; j + i + 1 < n; ++j)
  {
    if (a[j] > a[j + 1]) std::swap(a[j], a[j + 1]);
  }
}
```

## Selection Sort

- $n - 1$ iterations are performed.
- In the $i$-th iteration, the elements $a_i \dots a_n$ are processed.
- Among the processed elements, the **minimum** is selected, let's say it is the element $a_p$.
- The elements $a_i$ and $a_p$ are swapped.

Thus, an invariant is maintained - after the $i$-th iteration, the prefix $a_1 \dots a_i$ is sorted.

The worst-case complexity is $O(n + (n - 1) + \dots + 1) = O(n^2)$ comparisons.

A modification of this sort to $O(n \cdot \log{n})$ is _heap sort_.

### Implementation

Example implementation in C++:

```cpp
for (size_t i = 0; i + 1 < n; ++i)
{
  auto it = std::min_element(a.begin() + i, a.end());
  std::swap(a[i], *it);
}
```

## Insertion Sort

- $n - 1$ iterations are performed.
- In the $i$-th iteration, the elements $a_1 \dots a_i$ are processed.
- The element $a_i$ is sequentially swapped with $a_{i - 1}, a_{i - 2}, \dots$ until the prefix $a_1 \dots a_i$ becomes sorted.

Thus, an invariant is maintained - after the $i$-th iteration, the prefix $a_1 \dots a_i$ is sorted.

The worst-case complexity is $O(1 + 2 + \dots + (n - 1) + n) = O(n^2)$ comparisons.

A modification of this sort to $O(n \cdot \log{n})$ is _merge sort_.

### Implementation

Example implementation in C++:

```cpp
for (size_t i = 0; i + 1 < n; ++i)
{
  for (size_t j = i; j > 0 && a[j - 1] > a[j]; --j)
  {
    std::swap(a[j - 1], a[j]);
  }
}
```