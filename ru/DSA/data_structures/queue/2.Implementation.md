# Implementation

## Linked list

Очередь может быть основана на любом связном списке, deque явно требует двусвязный.

Связный список реализует все необходимые операции по умолчанию без каких-либо модификаций.

## Dynamic array

На основе динамического массива очередь / deque реализуется чуть сложнее, чем стек.

Заведём два указателя - `head` ($h$) и `tail` ($t$).

В таком случае все элементы будут лежать внутри полуинтервала $[h; t)$:

Вставка / удаление значений в начало / конец реализуются через сдвиги соответствующих указателей:

- `push_back` увеличивает $t$, `push_front` - уменьшает $h$;
- `pop_back` уменьшает $t$, `pop_front` - увеличивает $h$.

### Indexing

Можно заметить, что реализация на динамическом массиве добавляет возможность индексироваться по очереди:

- `at(pos)` по сути обращается к $h + pos$ элементу внутреннего массива.

### Circular buffer

Допустим, что в данный момент `capacity` нашего массива равно $C$.

При попытке вставить элемент в конец, когда $T = C$, мы будем вынуждены перевыделить массив.

Но если, например, $H = T - 1$, то кажется небольшим расточительством перевыделять массив, когда почти вся память не используется.

Для оптимизации расхода памяти используется **циклический буфер**:

- при достижении $h$ / $t$ конца массива они продолжают своё движение в начале (и наоборот).
- буфер считается заполненным, когда $t = (h - 1 + C)$ % $C$.
  - в таком случае выделение массива большего размера - реально единственный способ вставить новый элемент.

## Блочная реализация

Заметим, что в общем случае можно объединить идеи циклического буфера и связного списка.

Основой будет циклический буфер указателей, но каждый указатель будет указывать на массив маленького (зачастую фиксированного) размера.

Такая реализация имеет свои плюсы и минусы:

- с одной стороны, блочное хранение данных позволяет более гибко подходить к выделению памяти при вставке новых элементов.
- с другой, в отличие от простого вектора данные "разбросаны" по памяти небольшими кусками, что может не так хорошо сказываться на работе с кешем.

По сути блочная реализация находится в различных аспектах где-то посередине между чистым связным списком и динамическим массивом.

## Два стека

Достаточно экзотический способ реализации **очереди** (не deque), но находит применение в некоторых специальных задачах.

Заведём два стека:

- в один (хвостовой) будем вставлять элементы - операция очереди `push`;
- из второго (головного) будем извлекать элементы - операции очереди `pop` / `front`.

### Как это работает?

Как вставить элемент в хвостовой стек - понятно. Но как элементы из хвостового стека попадут в головной?

Не будем изобретать никаких ухищрений: если на момент запроса извлечения головной стек пуст, то честно в цикле перекинем туда все элементы из хвостового.

Обратите внимание, что в таком случае наверху головного стека окажется элемент, который был вставлен **раньше всего** в хвостовой (что даст нам желаемый FIFO).

### Почему это работает эффективно?

Применим бухгалтерский способ оценки сложности.

Выдадим каждому вставляемому значению $4$ монеты:
  - на вставку в хвостовой стек;
  - на извлечение из хвостового стека;
  - на вставку в головной стек;
  - на извлечение из головного стека.

Таким образом, на $Q$ операций вставки / извлечения мы потратим не более $4 \cdot Q = O(Q)$ монет, что даёт **амортизированную оценку** $O(1)$ на одну операцию.

### Пример реализации

```cpp
template<typename T>
struct QueueTwoStacks
{
  std::stack<T> head, tail;

  void ensure_head()
  {
    // important condition!
    if (head.empty())
    {
      while (!tail.empty())
      {
        head.push(tail.top());
        tail.pop();
      }
    }
  }

  T front() const
  {
    ensure_head();

    // UB if queue empty
    return head.top();
  }

  void push(const T& value)
  {
    tail.push(value);
  }

  void pop()
  {
    ensure_head();

    // UB if queue empty
    head.pop();
  }
};
```
