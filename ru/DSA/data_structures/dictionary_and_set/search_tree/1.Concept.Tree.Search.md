# Деревья поиска

Само по себе дерево - это лишь способ представления данных и их связей.

Одним из применений деревьев является хранение данных с реализацией следующих операций:

- добавление значения;
- удаление значения;
- поиск узла с заданным значением;
- перебор всех хранимых значений.

Деревья, эффективно выполняющие такие операции, называют **деревьями поиска**.

## Связь с множеством и словарём

Можно легко заметить, что основные операции дерева поиска совпадают с операциями абстракций словаря и множества (при дополнительном условии уникальности хранимых значений):

- в случае множества узлы хранят соответствующие элементы множества;
- в случае словаря узлы хранят пары (ключ, значение), но поиск производится по ключу.

Обратите внимание, что в этом случае на тип данных элементов множества / ключей словаря накладывается требование сравнимости (вспомните лекцию про сортировки и компараторы).

## Какие бывают деревья поиска?

Чаще всего деревья поиска являются двоичными и сбалансированными.

В общем случае дерево не обязано быть двоичным (например, в "2-3 дереве" у каждого узла соответственно $2$ или $3$ ребенка).

Сбалансированность тоже формально не обязательна, но в подавляющем большинстве случаев именно у сбалансированных деревьев наилучшая асимптотика приведенных выше операций.

## Двоичные деревья поиска (ДДП)

В двоичном дереве поиска для любой вершины $v$ выполняется правило:

- пусть в вершине $v$ хранится значение $k$;
- для всех вершин $vl$ в левом поддереве вершины $v$ верно, что их значение $kl \le k$;
- для всех вершин $vr$ в правом поддереве вершины $v$ верно, что их значение $kr \ge k$.

### Основные операции над ДДП

#### Самый глубокий узел при спуске

**Вспомогательная** операция (обычно имеет уровень доступа `private` или аналогичный).

Пусть нам дано значение $x$. Необходимо найти самый глубокий узел, путь до которого совпадает с путём до узла со значением $x$.

Для этого заведём параметр `last` - последний узел, обработанный перед текущим узлом.

- если текущий узел отсутствует - поиск завершен, возвращаем `last`.
- обновляем `last` текущим узлом.
- если значение $k$ в текущем узле больше $x$ - продолжаем поиск в левом поддереве;
- если значение $k$ в текущем узле меньше $x$ - продолжаем поиск в правом поддереве.

Пример нерекурсивной реализации:

```cpp
Node* _get_last(Node* start, const T& value) {
  Node* last = nullptr;
  for (Node* node = start; node != nullptr; ) {
    last = node;

    if (value < node->value) node = node->left;
    else node = node->right;
  }

  return last;
}
```

#### Поиск значения

Найдем самый глубокий узел через спуск. Если в найденном узле искомое значение - вернем узел как результат.

Пример нерекурсивной реализации:

```cpp
Node* _find(Node* start, const T& value) {
  Node* last = _get_last(start, value);

  if (last != nullptr && last->value == value) return last;

  return nullptr;
}

Node* find(const T& value) {
  return _find(root, value);
}
```

При рекурсивной реализации спуск объединяется с поиском:

```cpp
Node* _find(Node* node, const T& value) {
  if (node == nullptr) return node;

  if (value == node->value) return node;

  if (value < node->value) return find(node->left);
  else return find(node->right);
}
```

#### Вставка значения

Найдем самый глубокий узел через спуск. Добавим новый узел слева или справа в зависимости от вставляемого значения.

Также не забудьте обновить корень, если до этого дерево было пустым.

Пример нерекурсивной реализации:

```cpp
Node* _insert(Node* start, Node* new_node) {
  Node* last = _get_last(start, value);

  if (last != nullptr) {
    if (value < last->value) last->left = new_node;
    else last->right = new_node;

    new_node->parent = last;
  } else {
    start = new_node; // tree was empty
  }

  return start;
}

Node insert(const T& value) {
  Node* new_node = create_node(value);

  root = _insert(root, new_node);
}
```

При рекурсивной реализации происходит обновление всех связей на возврате:

```cpp
Node* _insert(Node* node, Node* new_node) {
  if (node == nullptr) return new_node;

  if (new_node->value < node->value) {
    node->left = _insert(node->left, new_node);
  } else {
    node->right = _insert(node->right, new_node);
  }

  return node;
}
```

#### Обход ДДП

ДДП обычно обходят в порядке LVR - в таком случае значения обходятся в порядке **неубывания**.

В таком случае `first` и `last` задают, соответственно, самые левые и правые узлы дерева (выполняются через спуск).

Пример реализации функции `next` для обхода в порядке LVR уже описан в разделе про [нерекурсивные обходы двоичных деревьев](#нерекурсивный-вариант-полного-обхода).

#### Поиск ближайшего большего значения

Найдём самый глубокий узел через спуск.

- Если искомое значение больше либо равно значения в найденном узле - перейдём к следующему с помощью операции `next`.

Заметим, что в общем случае данный поиск имеет $4$ вариации:

- ближайшее большее / меньшее значение;
- строгое / нестрогое неравенство.

Пример нерекурсивной реализации:

```cpp
Node* _find_greater(Node* start, const T& value) {
  Node* last = _get_last(start, value);

  if (last->value <= value) {
    last = next(last);
  }

  return last;
}

Node* find_greater(const T& value) {
  return find_greater(root, value);
}
```

#### Удаление значения

Необходимо удалить узел $v$ с заданным значением.

- С помощью спуска найдем искомый узел.
- Если у узла $v$ менее двух детей, то просто заменим его имеющимся сыном.

- Иначе найдем узел $x$, следующий после $v$ в порядке обхода.
  - Так как в данной ситуации у узла $v$ есть правый ребенок, то узел $x$ фактически "самый левый в правом поддереве $v$ ".
- Перенесем данные из $x$ в $v$, после чего **рекурсивно** вызовем удаление $x$ из правого поддерева узла $v$.

Пример рекурсивной реализации:

```cpp
Node* _erase(Node* node, const T& value) {
  if (value < node->value) {
    node->left = _erase(node->left, value);
    return node;
  }

  if (del_node->value > node->value) {
    node->right = _erase(node->right, del_node);
    return node;
  }

  // del_node->value == node->value

  if (del_node->left == nullptr) {
    Node* right_child = del_node->right;

    delete del_node;
    return right_child;
  }

  if (del_node->right == nullptr) {
    Node* left_child = del_node->left;

    delete del_node;
    return left_child;
  }

  // both children

  Node* next_node = next(del_node);
  del_node->value = next_node->value;

  del_node->right = _erase(del_node->right, next_node);

  return del_node;
}
```

### Сбалансированные ДДП

Легко заметить, что все операции с ДДП (кроме полного обхода) выполняются за $O(H)$ (так как основаны на операции спуска).

Чтобы операции были эффективными, высота дерева должна быть как можно меньше.

Поэтому чаще всего стремятся использовать именно сбалансированные ДДП с высотой $H = O(\log{N})$.

#### Статическое сбалансированное ДДП

Дан массив значений $a_i$ длины $N$.

Необходимо построить сбалансированное ДДП по данному массиву и отвечать только на операции поиска.

- отсортируем массив $a_i$ за $O(N \log{N})$.
- найдем позицию медианы массива $M = \frac{N}{2}$ и поставим значение $a_M$ в корень дерева.
- **рекурсивно** построим левые и правые поддеревья на основе $a_1 \dots a_{M - 1}$ и $a_{M + 1} \dots a_N$ соответственно.

Итоговое дерево будет сбалансированно по размеру поддеревьев.

#### Самобалансирующиеся ДДП

Чаще всего в задаче всё-таки подразумеваются операции вставки и удаления.

В таком случае сбалансированность может легко нарушаться - вследствие чего высота дерева из $O(\log{N})$ может выродиться вплоть до $O(N)$.

Для таких ситуаций используют так называемые **самобалансирующиеся** деревья поиска.

Такие деревья используют специальные операции по поддержанию своих инвариантов баланса - поэтому их высота всегда гарантированно $O(\log{N})$ (кроме специфичных примеров).

Описано большое количество самобалансирующихся деревьев: AVL-дерево, 2-3 дерево (не совсем двоичное), красно-чёрное дерево и многие-многие другие.

##### "Почти сбалансированное" ДДП без вставок

Дан массив значений $a_i$ длины $N_0$.

Необходимо построить сбалансированное ДДП по данному массиву и отвечать только на операции поиска и **удаления**.

- Такая задача может, очевидно, быть решена эффективно любым самобалансирующимся деревом поиска с операциями за $O(\log{N})$, где $N$ - текущий размер дерева.

- В то же время можно заметить, что операция удаления может только **уменьшить** текущую высоту дерева. Таким образом, можно построить статическое сбалансированное ДДП (см. выше), после чего производить операции удаления без дополнительных модификаций дерева.

  При такой реализации асимптотика операций будет равна $O(\log{N_0})$ - не совсем сбалансированно, но зачастую достаточно эффективно.