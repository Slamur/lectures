# Деревья поиска

Само по себе дерево - это лишь способ представления данных и их связей.

Одним из применений деревьев является хранение данных с реализацией следующих операций:

- добавление значения;
- удаление значения;
- поиск узла с заданным значением;
- перебор всех хранимых значений.

Деревья, эффективно выполняющие такие операции, называют **деревьями поиска**.

## Связь с множеством и словарём

Можно легко заметить, что основные операции дерева поиска совпадают с операциями абстракций словаря и множества (при дополнительном условии уникальности хранимых значений):

- в случае множества узлы хранят соответствующие элементы множества;
- в случае словаря узлы хранят пары (ключ, значение), но поиск производится по ключу.

Обратите внимание, что в этом случае на тип данных элементов множества / ключей словаря накладывается требование сравнимости (вспомните лекцию про сортировки и компараторы).

## Какие бывают деревья поиска?

Чаще всего деревья поиска являются двоичными и сбалансированными.

В общем случае дерево не обязано быть двоичным (например, в "2-3 дереве" у каждого узла соответственно $2$ или $3$ ребенка).

Сбалансированность тоже формально не обязательна, но в подавляющем большинстве случаев именно у сбалансированных деревьев наилучшая асимптотика приведенных выше операций.

## Двоичные деревья поиска (ДДП)

В двоичном дереве поиска для любой вершины $v$ выполняется правило:

- пусть в вершине $v$ хранится значение $k$;
- для всех вершин $vl$ в левом поддереве вершины $v$ верно, что их значение $kl \le k$;
- для всех вершин $vr$ в правом поддереве вершины $v$ верно, что их значение $kr \ge k$.

### Основные операции над ДДП

#### Самый глубокий узел при спуске

**Вспомогательная** операция (обычно имеет уровень доступа `private` или аналогичный).

Пусть нам дано значение $x$. Необходимо найти самый глубокий узел, путь до которого совпадает с путём до узла со значением $x$.

Для этого заведём параметр `last` - последний узел, обработанный перед текущим узлом.

- если текущий узел отсутствует - поиск завершен, возвращаем `last`;
- обновляем `last` текущим узлом; 
- если значение $k$ в текущем узле равно $x$ и установлен флаг `stop_on_equal` - поиск завершен, возвращаем `last`;
- если значение $k$ в текущем узле больше $x$ - продолжаем поиск в левом поддереве;
- если значение $k$ в текущем узле меньше $x$ - продолжаем поиск в правом поддереве.

Пример нерекурсивной реализации:

```cpp
Node* _get_last(Node* start, const T& value, bool stop_on_equal = false) {
    Node* last = nullptr;
    for (Node* node = start; node != nullptr; ) {
        last = node;
        
        if (value == node->value && stop_on_equal) {
            break;
        }
    
        if (value < node->value) node = node->left;
        else node = node->right;            
    }

    return last;
}
```

#### Поиск значения

Найдем самый глубокий узел через спуск, но остановимся на первом узле с искомым значением. 

Если в найденном узле искомое значение - вернем узел как результат.

Пример API:

```cpp
Node* find(const T& value) {
    return _find(root, value);
}
```

Пример нерекурсивной реализации:

```cpp
Node* _find(Node* start, const T& value) {
    Node* last = _get_last(start, value, true);
    
    if (last != nullptr && last->value == value) return last;
    
    return nullptr;
}
```

При рекурсивной реализации спуск объединяется с поиском:

```cpp
Node* _find(Node* node, const T& value) {
    if (node == nullptr) return node;
    
    if (value == node->value) return node;
    
    if (value < node->value) return find(node->left);
    else return find(node->right);
}
```

#### Вставка значения

Найдем самый глубокий узел через спуск. Добавим новый узел слева или справа в зависимости от вставляемого значения.

Также не забудьте обновить корень, если до этого дерево было пустым.

Пример API:

```cpp
Node* insert(const T& value) {
    Node* new_node = create_node(value);

    if (root == nullptr) {
        root = new_node;
    } else {
        _insert(root, new_node);
    }
    
    return new_node;
}
```

Пример нерекурсивной реализации:

```cpp
void _insert(Node* start, Node* new_node) {
    Node* last = _get_last(start, value);
    
    if (last != nullptr) {
        if (value < last->value) last->left = new_node;
        else last->right = new_node;
        
        new_node->parent = last;
    }
}
```

При рекурсивной реализации происходит обновление всех связей на возврате:

```cpp
Node* _insert(Node* node, Node* new_node) {
    if (node == nullptr) return new_node;
    
    if (new_node->value < node->value) {
        node->left = _insert(node->left, new_node);
    } else {
        node->right = _insert(node->right, new_node);
    }
    
    return node;
}
```

#### Обход ДДП

ДДП обычно обходят в порядке LVR - в таком случае значения обходятся в порядке **неубывания**.

В таком случае `first` и `last` задают, соответственно, самые левые и правые узлы дерева (выполняются через спуск).

Пример реализации функции `next` для обхода в порядке LVR уже описан в разделе про [нерекурсивные обходы двоичных деревьев](./../../tree/2.Concept.Tree.Binary.md#нерекурсивный-вариант-полного-обхода).

#### Поиск ближайшего большего значения

Найдём самый глубокий узел через спуск.

- Если искомое значение больше либо равно значения в найденном узле - перейдём к следующему с помощью операции `next`.

Заметим, что в общем случае данный поиск имеет $4$ вариации:

- ближайшее большее / меньшее значение;
- строгое / нестрогое неравенство.

Пример API:

```cpp
Node* find_greater(const T& value) {
    return find_greater(root, value);
}
```

Пример нерекурсивной реализации:

```cpp
Node* _find_greater(Node* start, const T& value) {
  Node* last = _get_last(start, value);

  if (last->value <= value) {
    last = next(last);
  }

  return last;
}
```

#### Удаление значения

Необходимо удалить узел с заданным значением $val$.

- С помощью спуска найдем искомый узел $v$.
- Если у узла $v$ менее двух детей, то просто заменим его имеющимся сыном.

- Иначе найдем узел $x$, следующий после $v$ в порядке обхода.
  - Мы знаем, что у узла $v$ есть оба сына, а значит узел $x$ является самым левым в правом поддереве узла $v$. 
    - В том числе это значит, что у узла $x$ не может быть левого ребенка (иначе он не был бы самым левым).
- Обменяем данные из $x$ в $v$, после чего **рекурсивно** вызовем удаление $val$ из правого поддерева узла $v$.
  - Так как у $x$ нет левого ребенка, то при удалении мы попадем в первый случай (менее двух детей).

Пример API:

```cpp
void erase(const T& value) {
    root = _erase(root, value);
}
```

Пример рекурсивной реализации:

```cpp
Node* _erase(Node* node, const T& value) {
    if (value < node->value) {
        node->left = _erase(node->left, value);
        return node;
    }
    
    if (value > node->value) {
        node->right = _erase(node->right, value);
        return node;
    }
    
    // value == node->value
    
    if (node->left == nullptr || node->right == nullptr) {
        // at most one child
        Node* child = (node->left != nullptr) ? node->left : node->right;
        
        delete node;
        return child;
    }
    
    // both children
    
    Node* next_node = next(node);
    std::swap(node->value, next_node->value);
    
    node->right = _erase(node->right, value);
    
    return node;
}
```

### Сбалансированные ДДП

Легко заметить, что все операции с ДДП (кроме полного обхода) выполняются за $O(H)$ (так как основаны на операции спуска).

Чтобы операции были эффективными, высота дерева должна быть как можно меньше.

Поэтому чаще всего стремятся использовать именно сбалансированные ДДП с высотой $H = O(\log{N})$.

#### Статическое сбалансированное ДДП

Дан массив значений $a_i$ длины $N$.

Необходимо построить сбалансированное ДДП по данному массиву и отвечать только на операции поиска.

- отсортируем массив $a_i$ за $O(N \log{N})$.
- найдем позицию медианы массива $M = \frac{N}{2}$ и поставим значение $a_M$ в корень дерева.
- **рекурсивно** построим левые и правые поддеревья на основе $a_1 \dots a_{M - 1}$ и $a_{M + 1} \dots a_N$ соответственно.

Итоговое дерево будет сбалансированным по размеру поддеревьев.

#### Самобалансирующиеся ДДП

Чаще всего в задаче всё-таки подразумеваются операции вставки и удаления.

В таком случае сбалансированность может легко нарушаться - вследствие чего высота дерева из $O(\log{N})$ может выродиться вплоть до $O(N)$.

Для таких ситуаций используют так называемые **самобалансирующиеся** деревья поиска.

Такие деревья используют специальные операции по поддержанию своих инвариантов баланса - поэтому их высота всегда гарантированно $O(\log{N})$ (кроме специфичных примеров).

Описано большое количество самобалансирующихся деревьев: AVL-дерево, 2-3 дерево (не совсем двоичное), красно-чёрное дерево и многие-многие другие.

##### "Почти сбалансированное" ДДП без вставок

Дан массив значений $a_i$ длины $N_0$.

Необходимо построить сбалансированное ДДП по данному массиву и отвечать только на операции поиска и **удаления**.

- Такая задача может, очевидно, быть решена эффективно любым самобалансирующимся деревом поиска с операциями за $O(\log{N})$, где $N$ - текущий размер дерева.

- В то же время можно заметить, что операция удаления может только **уменьшить** текущую высоту дерева. Таким образом, можно построить статическое сбалансированное ДДП (см. выше), после чего производить операции удаления без дополнительных модификаций дерева.

При такой реализации асимптотика операций будет равна $O(\log{N_0})$ - дерево получается не совсем сбалансированным, но зачастую данной асимптотики достаточно.