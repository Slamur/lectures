## Эффективность алгоритма

Представим ситуацию: вы прочли задачу и быстро придумали к ней простой алгоритм решения. Реализовали его на любимом ЯП, после чего отправили в тестирующую систему.

И получили вердикт "Превышено ограничение времени"...

Чаще всего это связано с недостаточной **эффективностью** вашего алгоритма.

Но как вы должны были это понять?! Как вы могли до написания и отправки кода в систему понять, что ваше решение выйдет за ограничения по времени?

**Ответ**: оценить количество простых операций.

### Простые операции и скорость их выполнения

Одной из важных характеристик компьютера является **тактовая частота** процессора (измеряется в герцах).

Эта величина показывает, сколько "тактов" успевает обработать процессор за одну секунду.

По сути такты - это единицы дискретного времени для процессора.

Современные процессоры выполняют **миллиарды тактов** в секунду (то есть их тактовая частота измеряется уже в **гига**герцах).

#### Одна операция - много тактов

Такт является элементарной единицей выполнения, за которую выполняются базовые машинные операции.

Но если говорить про обычные "базовые" операции в вашем ЯП, то  ?????????????????????

Самый частый способ оценки времени работы вашей программы - оценка количества выполняемых ею простых операций.

В настоящее время используется приблизительная оценка, что за 1 секунду выполняется порядка 10^8 операций. Обратите внимание, что нас не интересует точное количество операций, нас интересует лишь порядок. 

В идеале порядок количества операций должен быть на 1-2 порядка меньше максимума - тогда вам не придется думать о более точной оценке, и так будет понятно, что работает быстро. 

С другой стороны очевидно, что если программа выполняет порядка 10^10 операций, то в секунду она не уложится никак, да и в 2 секунды тоже) (здесь и далее мы будем рассматривать только работу на тестах, на которых программа выполняется максимально возможное время - оценка по худшему случаю).

Обозначим за T(N) - количество операций алгоритма, который принимает на вход вектор параметров N - N1, N2, ..., NK.

Определение: T(N) = O(F(N)) - “О большое”, если существует такая константа C > 0, 
что T(N)  F(N) * C для всех NN0 > 0.

Обратите внимание, что “О большое” - верхняя оценка. Поэтому она может работать с неодинаковыми по виду функциями (хотя обычно вам это не понадобится).

Определение: Назовем функцию F(N) асимптотикой алгоритма с количеством операций T(N), если 
T(N) = O(F(N)), 
F(N) = O(T(N)) (иногда нет, но это очень узкие случаи), 
F(N) содержит лишь несравнимые слагаемые. Коэффициенты при слагаемых равны 1.
F(N) не содержит слагаемых, не зависящих от параметров функции (если вам очень надо, чтобы содержала - вероятно, что вы не учитываете какой-то параметр)

Определение: Слагаемые X(N) и Y(N) функции F(N) назовём несравнимыми, если 
X(N) != O(Y(N))
Y(N) != O(X(N))

Итог: Чтобы оценить время работы вашей программы, вам достаточно оценить ее асимптотику и, подставив в неё значения параметров в худшем случае, выяснить оценочное число операций.

Пример 0: 
T(N) = 3 * N^2 + 2
F(N) = N^2
F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
	- T(N) = O(F(N)) - (3 * N^2 + 2) 4 * N^2 для N  2
	- F(N) = O(T(N)) - N^2  1 * (3 * N^2 + 2) для N  1
	- Коэффициент при слагаемом N^2 равен 1.

Пример 1: 
T(N) = N^2 + 3 * MN + M^3 / 10 + 100 * M^2 + 20
F(N) = N^2 + MN + M^3
F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
	- T(N) = O(F(N))
	- F(N) = O(T(N)) 
	- Коэффициенты при слагаемых N^2, MN, M^3 равны 1; 
- M^3 сравнимо с M^2, поэтому M^2 не включено в F(N).
	- 20 не зависит от параметров, поэтому 20 не включено в F(N).

Пример 2:
	T(N) = 3 * N^2 + 2
	F(N) = N^3
	F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- F(N) != O(T(N)) - N^3  C * (3 * N^2 + 2) для любого значения C для N 2 * С - противоречие с определением

Пример 3:
	T(N) = 3 * N^2 + 2.
F(N) = N
	F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- T(N) != O(F(N)) - (3 * N^2 + 2)  С * N для N  С - противоречие с определением

Пример 4:
	T(N) = 3 * N^2 + 2
	F(N) = 2 * N^2
F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- коэффициент при слагаемом N^2 равен 2 - противоречие с определением

Пример 5:
	T(N) = 3 * N^2 + 2
	F(N) = N^2 + N
F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- F(N) содержит сравнимые слагаемые N^2 и N - противоречие с определением

Пример 6:
	T(N) = 3N^2 + 50N + 200
	F(N) = N^2

F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
Выберем C = 4 

	3N^2 + 50N + 200 <= 4N^2
	N^2 - 50N - 200 >= 0
	D = 625 + 200 = 825
	N >= (25 + sqrt(D)) > 53

	T(54) = 11648, C * F(54) = 4 * 54^2 = 11664 - верно

Обратите внимание: хотя на мелких данных T(N) сильно больше C * F(N), но, начиная с N = 54, T(N) <= C * F(N) - и так до бесконечности.
Рассмотрим асимптотики, с помощью комбинации которых можно задать асимптотику практически любого алгоритма:

	1. O(1) - простейшая операция - +, *, обращение по индексу к массиву и так далее - вообще не зависит от N.

	2. O(logN) - логарифм от N. 

Определение: Логарифм: если a^b = c, то log_a(c) = b. 
Логарифм растет очень медленно (log_2(10^18) <= 60).

Основание логарифма не пишут, так как log_a(b) = log_c(b) / log_c(a), где 1 / log_c(a) - константа, не зависящая от b. 

	3. O(N^k) - полиномиальная зависимость.

	4. O(a^N) - экспоненциальная зависимость. Здесь число a имеет значение, так как при переходе от a^n к b^n появляется коэффициент (a / b) ^ n, зависящий от n.

	5. O(N!) - факториал от N - очень быстро растет, но и решения с такой асимптотикой бывают.
	
Распишем частные случаи асимптотик и примерные значения N, при которых такая асимптотика еще позволит вам уложиться в 1 секунду:

	1. O(1) - любое N;
	2. O(logN) - любое N, влезающее в стандартные типы данных - слишком медленно растет :D
	3. O(N^(1 / 2)), O(N^(1 / 3)) - квадратный и кубический корни из N - растет медленно, но растет - 10^15-10^16 для квадратного корня и 10^18 для кубического;
	4. O(N) - "линия" - 10^7 - 10^8;
	5. O(N * logN) - "Н лог Н" - 10^5 - 10^6 (зависит от основания логарифма и опущенной константы).
	6. O(N * sqrt(N)) - 10^5.
	7. O(N^2) - "квадрат" - 10^4;
	8. O(N^3) - "куб" - 300 - 500;
	9. O(2^N), O(N * 2^N) - 20 - 24 (при 23-24 на грани).
	10. O(3^N) - примерно 14-16.
	11. O(1.5 ^ N) - 1.5 - приближение числа (1 + sqrt(5)) / 2 - это скорость роста значений чисел Фибоначчи - примерно 30 (хз, точно не считал, лучше на калькуляторе проверять).

Рассмотрим несколько частных примеров вычисления асимптотики:

	1. Последовательное выполнение алгоритмов.
	
		function T(N) {
			F(N);
			G(N);
		}	
	
В таком случае асимптотика T(N) будет равна O(F(N) + G(N)).
	
	2. Циклическое выполнение какого-либо алгоритма.
	
		for (int i = 0; i < M; ++i) {
			F(N);
		}
		
Проводя аналогии с предыдущим примером, здесь мы M раз выполняем алгоритм с асимптотикой O(F(N)), итого O(M) * O(F(N)) = O(M * F(N)).
	
	3. Циклическое уменьшение/увеличение величины в A раз.
	
		function F(N) {
			result = 0;
			while (N > 0) {
				N /= A;
				result = result + 1;
			}
			
			return result;
		}
		
Здесь result будет равно минимальной степени A, при которой A^(result - 1) <= N < A^(result), откуда result = log_A(N) и асимптотика F(N) = O(result) = O(logN).
Для закрепления материала предлагаем вам подумать над асимптотикой алгоритмов для решения следующих задач (операции сложения, сравнения и подобные делаются за O(1)):

	1.  Найти сумму элементов массива A длины N. 
	2.  Найти максимум, минимум в массиве A длины N; найти и максимум, и минимум одновременно - различаются ли оценки для этих заданий? 
	3.  Вывести все цифры числа Х через пробел (в оценке должен быть только Х).
	4.  Найти точку M - центр отрезка AB по координатам точек A и B (в двумерной плоскости)
	5.  Найти индекс строки матрицы A из целых чисел размера NxM (N cтрок, в каждой M столбцов) с минимальной суммой; с минимальным первым элементом.
	6.  Сравнить лексикографически (в алфавитном порядке) две строки S1 и S2.

Ответы к данным задачам расположены на следующем листе.

Ответы на простые задачи:
O(N) - просто пробежимся циклом по массиву.
O(N); поиск минимума и максимума вместе можно сделать за 3N/2 операций (подумайте, как), но это все равно O(N).
Количество цифр в числе можно оценить максимальной степенью 10 в числе, а это логарифм - O(logN).
Точка вычисляется по формуле, а значит O(1).
Для каждой строки надо посчитать сумму за O(M), всего строк N, поэтому O(NM). Первый элемент ищется за O(1), значит во втором варианте O(N).
Строки сравниваются посимвольно, пока одна из строк не закончится, значит O(min(|S1|, |S2|)).

