# Эффективность алгоритма

Представим ситуацию: вы прочли задачу и быстро придумали к ней простой алгоритм решения. Реализовали его на любимом ЯП, после чего отправили в тестирующую систему.

И получили вердикт "Превышено ограничение времени"...

Чаще всего это связано с недостаточной **эффективностью** вашего алгоритма.

Но как вы должны были это понять?! Как вы могли до написания и отправки кода в систему понять, что ваше решение выйдет за ограничения по времени?

**Ответ**: оценить количество простых операций.

## Простые операции и скорость их выполнения

Одной из важных характеристик компьютера является **тактовая частота** процессора (измеряется в герцах).

Эта величина показывает, сколько "тактов" успевает обработать процессор за одну секунду.

По сути такты - это единицы дискретного времени для процессора.

Современные процессоры выполняют **миллиарды тактов** в секунду (то есть их тактовая частота измеряется уже в **гига**герцах).

### Одна операция - несколько тактов

Такт является элементарной единицей выполнения, за которую выполняются базовые машинные операции.

Но одна операция в вашем ЯП не всегда совпадает с одной машинной операцией.

Поэтому часто используется оценка в $10^8$ операций за секунду. Обратите внимание, что это не четкое ограничение - это по сути порядок величин, на который можно ориентироваться.

**Важно**: у всех ЯП различная производительность. Например, для Python рекомендуется в большинстве случаев ориентироваться на порядок $10^7$ операций. 

### И что делать с этими количествами?

Если для вашего алгоритма существует тест с наибольшим числом операций - авторы задачи постараются его добавить в набор. 

Соответственно дальнейшие рассуждения будут производиться относительно **худшего случая** для вашего алгоритма.

В идеале порядок количества операций должен быть меньше максимального на 1-2 - тогда вам не придется думать о более точной оценке, и так будет понятно, что работает быстро. 

С другой стороны, что если программа выполняет порядка $10^{12}$ операций, то в секунду она не уложится никак, да и в 2 секунды тоже.

## Асимптотика - оценка эффективности

Допустим, что у нас есть алгоритм, зависящий от одного целого числа $N$.

Обозначим через $T(N)$ функцию, вычисляющую количество операций нашего алгоритма для заданного $N$.

В большинстве случаев вычислять или определять конкретное значение $T(N)$ является затратным и не особо полезным.

Поэтому в программировании стараются использовать **оценку** количества операций - ведь зачастую вам важен лишь порядок, а не точное число.

### "О большое"

Введём **обозначение**: для какой-либо функции $F(N)$ будем говорить, что $T(N) = O(F(N))$,

если существуют такие константы $C > 0$ и $N_0 \ge 0$, что $T(N) \le C \cdot F(N)$ для всех $N \ge N_0$.

По сути “О большое” является обозначением **оценки сверху** для функции $T(N)$ через функцию $F(N)$. 

#### А если у алгоритма несколько параметров?

В общем случае можно считать, что "О большое" должно работать для каждого параметра независимо (или для какой-либо их комбинации).

Соответственно, в дальнейшем под $N$ будет пониматься любой набор числовых параметров алгоритма $N_1, N_2, \dots, N_k$.

#### Другие обозначения

Аналогично "О большому" существуют обозначения для других видов оценки - [таблица в статье](https://ru.wikipedia.org/wiki/«O»_большое_и_«o»_малое) Википедии.

### Определение асимптотики

Будем называть функцию $F(N)$ **асимптотикой** алгоритма с количеством операций $T(N)$, если 

- $T(N) = O(F(N))$, 
- $F(N) = O(T(N))$ (иногда нет, но это очень узкие случаи), 
- $F(N)$ содержит лишь **несравнимые** слагаемые.
- Коэффициенты при слагаемых равны $1$.
- $F(N)$ не содержит слагаемых и множителей, не зависящих от параметров алгоритма (если у вас такие есть, то сделайте их параметрами).

**Определение**: Слагаемые X(N) и Y(N) функции F(N) назовём **несравнимыми**, если 

- X(N) != O(Y(N))
- Y(N) != O(X(N))

### Зачем нужна асимптотика?

В качестве асимптотики $F(N)$ зачастую берутся простые для вычисления функции.

Соответственно, подставляя в данную функцию значения параметров алгоритма $N$, вы можете **оценить** ожидаемое количество операций без сложных вычислений и анализа.

Оценка позволит вам понять, насколько вероятно ваше решение пройдет заданные ограничения по времени и памяти (зачастую или "точно пройдет", или "точно не пройдет").

## Примеры вычисления асимптотики

Пример 0: 
T(N) = 3 * N^2 + 2
F(N) = N^2
F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
	- T(N) = O(F(N)) - (3 * N^2 + 2) 4 * N^2 для N  2
	- F(N) = O(T(N)) - N^2  1 * (3 * N^2 + 2) для N  1
	- Коэффициент при слагаемом N^2 равен 1.

Пример 1: 
T(N) = N^2 + 3 * MN + M^3 / 10 + 100 * M^2 + 20
F(N) = N^2 + MN + M^3
F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
	- T(N) = O(F(N))
	- F(N) = O(T(N)) 
	- Коэффициенты при слагаемых N^2, MN, M^3 равны 1; 
- M^3 сравнимо с M^2, поэтому M^2 не включено в F(N).
	- 20 не зависит от параметров, поэтому 20 не включено в F(N).

Пример 2:
	T(N) = 3 * N^2 + 2
	F(N) = N^3
	F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- F(N) != O(T(N)) - N^3  C * (3 * N^2 + 2) для любого значения C для N 2 * С - противоречие с определением

Пример 3:
	T(N) = 3 * N^2 + 2.
F(N) = N
	F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- T(N) != O(F(N)) - (3 * N^2 + 2)  С * N для N  С - противоречие с определением

Пример 4:
	T(N) = 3 * N^2 + 2
	F(N) = 2 * N^2
F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- коэффициент при слагаемом N^2 равен 2 - противоречие с определением

Пример 5:
	T(N) = 3 * N^2 + 2
	F(N) = N^2 + N
F(N) не является асимптотикой для алгоритма с количеством операций T(N).

Доказательство:
	- F(N) содержит сравнимые слагаемые N^2 и N - противоречие с определением

Пример 6:
	T(N) = 3N^2 + 50N + 200
	F(N) = N^2

F(N) является асимптотикой алгоритма с количеством операций T(N).

Доказательство:
Выберем C = 4 

	3N^2 + 50N + 200 <= 4N^2
	N^2 - 50N - 200 >= 0
	D = 625 + 200 = 825
	N >= (25 + sqrt(D)) > 53

	T(54) = 11648, C * F(54) = 4 * 54^2 = 11664 - верно

Обратите внимание: хотя на мелких данных T(N) сильно больше C * F(N), но, начиная с N = 54, T(N) <= C * F(N) - и так до бесконечности.
Рассмотрим асимптотики, с помощью комбинации которых можно задать асимптотику практически любого алгоритма:

	1. O(1) - простейшая операция - +, *, обращение по индексу к массиву и так далее - вообще не зависит от N.

	2. O(logN) - логарифм от N. 

Определение: Логарифм: если a^b = c, то log_a(c) = b. 
Логарифм растет очень медленно (log_2(10^18) <= 60).

Основание логарифма не пишут, так как log_a(b) = log_c(b) / log_c(a), где 1 / log_c(a) - константа, не зависящая от b. 

	3. O(N^k) - полиномиальная зависимость.

	4. O(a^N) - экспоненциальная зависимость. Здесь число a имеет значение, так как при переходе от a^n к b^n появляется коэффициент (a / b) ^ n, зависящий от n.

	5. O(N!) - факториал от N - очень быстро растет, но и решения с такой асимптотикой бывают.
	
Распишем частные случаи асимптотик и примерные значения N, при которых такая асимптотика еще позволит вам уложиться в 1 секунду:

	1. O(1) - любое N;
	2. O(logN) - любое N, влезающее в стандартные типы данных - слишком медленно растет :D
	3. O(N^(1 / 2)), O(N^(1 / 3)) - квадратный и кубический корни из N - растет медленно, но растет - 10^15-10^16 для квадратного корня и 10^18 для кубического;
	4. O(N) - "линия" - 10^7 - 10^8;
	5. O(N * logN) - "Н лог Н" - 10^5 - 10^6 (зависит от основания логарифма и опущенной константы).
	6. O(N * sqrt(N)) - 10^5.
	7. O(N^2) - "квадрат" - 10^4;
	8. O(N^3) - "куб" - 300 - 500;
	9. O(2^N), O(N * 2^N) - 20 - 24 (при 23-24 на грани).
	10. O(3^N) - примерно 14-16.
	11. O(1.5 ^ N) - 1.5 - приближение числа (1 + sqrt(5)) / 2 - это скорость роста значений чисел Фибоначчи - примерно 30 (хз, точно не считал, лучше на калькуляторе проверять).

Рассмотрим несколько частных примеров вычисления асимптотики:

	1. Последовательное выполнение алгоритмов.
	
		function T(N) {
			F(N);
			G(N);
		}	
	
В таком случае асимптотика T(N) будет равна O(F(N) + G(N)).
	
	2. Циклическое выполнение какого-либо алгоритма.
	
		for (int i = 0; i < M; ++i) {
			F(N);
		}
		
Проводя аналогии с предыдущим примером, здесь мы M раз выполняем алгоритм с асимптотикой O(F(N)), итого O(M) * O(F(N)) = O(M * F(N)).
	
	3. Циклическое уменьшение/увеличение величины в A раз.
	
		function F(N) {
			result = 0;
			while (N > 0) {
				N /= A;
				result = result + 1;
			}
			
			return result;
		}
		
Здесь result будет равно минимальной степени A, при которой A^(result - 1) <= N < A^(result), откуда result = log_A(N) и асимптотика F(N) = O(result) = O(logN).
Для закрепления материала предлагаем вам подумать над асимптотикой алгоритмов для решения следующих задач (операции сложения, сравнения и подобные делаются за O(1)):

	1.  Найти сумму элементов массива A длины N. 
	2.  Найти максимум, минимум в массиве A длины N; найти и максимум, и минимум одновременно - различаются ли оценки для этих заданий? 
	3.  Вывести все цифры числа Х через пробел (в оценке должен быть только Х).
	4.  Найти точку M - центр отрезка AB по координатам точек A и B (в двумерной плоскости)
	5.  Найти индекс строки матрицы A из целых чисел размера NxM (N cтрок, в каждой M столбцов) с минимальной суммой; с минимальным первым элементом.
	6.  Сравнить лексикографически (в алфавитном порядке) две строки S1 и S2.

Ответы к данным задачам расположены на следующем листе.

Ответы на простые задачи:
O(N) - просто пробежимся циклом по массиву.
O(N); поиск минимума и максимума вместе можно сделать за 3N/2 операций (подумайте, как), но это все равно O(N).
Количество цифр в числе можно оценить максимальной степенью 10 в числе, а это логарифм - O(logN).
Точка вычисляется по формуле, а значит O(1).
Для каждой строки надо посчитать сумму за O(M), всего строк N, поэтому O(NM). Первый элемент ищется за O(1), значит во втором варианте O(N).
Строки сравниваются посимвольно, пока одна из строк не закончится, значит O(min(|S1|, |S2|)).

